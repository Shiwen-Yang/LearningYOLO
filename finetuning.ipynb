{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "from mss.linux import MSS as mss\n",
    "from ultralytics import YOLO\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset from huggingface that is in COCO (Common Objects in Context) format\n",
    "ds = load_dataset(\"keremberke/csgo-object-detection\", name=\"full\")\n",
    "\n",
    "# start training from scratch\n",
    "model_9m = YOLO(\"yolov9m.pt\").to(\"cuda\")\n",
    "model_9s = YOLO(\"yolov9s.pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(root, img_lab, train_val_test):\n",
    "    needed_path = root / img_lab / train_val_test\n",
    "    needed_path.mkdir(parents = True, exist_ok=True)\n",
    "    \n",
    "# writing a function that extracts the labels for each image in the dataset in YOLO format\n",
    "def save_img_label(df, train_val_test, output_dir, rounding = 6):\n",
    "    \n",
    "    output_dir_image = output_dir / \"images\"\n",
    "    output_dir_label = output_dir / \"labels\"\n",
    "    \n",
    "    # ensure the output directory exists\n",
    "    os.makedirs(output_dir_image, exist_ok = True)\n",
    "    os.makedirs(output_dir_label, exist_ok = True)\n",
    "    \n",
    "    for index, item in enumerate(df[train_val_test]):\n",
    "        current_obj = item['objects']\n",
    "        label = \"\"\n",
    "        for i, _ in enumerate(current_obj['category']):\n",
    "            name = current_obj['category'][i]\n",
    "            # the width and height of each picture is known to be 416 x 416, we need this to normalize everything\n",
    "            bbox = [np.round(x/416, rounding) for x in current_obj['bbox'][i]]\n",
    "            # bbox is in (xmin, ymin, width, height) format, we need to convert it to (xcenter, ycenter, width, height) format\n",
    "            xcenter = np.round(bbox[0] + bbox[2]/2, rounding)\n",
    "            ycenter = np.round(bbox[1] + bbox[3]/2, rounding)\n",
    "            \n",
    "            if name in [1,3]:\n",
    "                label = label\n",
    "            else: \n",
    "            # now we create the label\n",
    "                label += f\"0 {xcenter} {ycenter} {bbox[2]} {bbox[3]} \\n\"\n",
    "            \n",
    "        img = item['image']\n",
    "\n",
    "        output_path_label = os.path.join(output_dir_label / train_val_test, f\"{index}.txt\")\n",
    "        output_path_image = os.path.join(output_dir_image / train_val_test, f\"{index}.JPG\")\n",
    "        \n",
    "        \n",
    "        with open(output_path_label, 'w') as f:\n",
    "            f.write(label)\n",
    "            \n",
    "        img.save(output_path_image)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"yolo_data\")\n",
    "\n",
    "for i in [\"images\", \"labels\"]:\n",
    "    for j in [\"train\", \"validation\", \"test\"]:\n",
    "        make_folders(root_path, i, j)\n",
    "        \n",
    "for i in [\"train\", \"validation\", \"test\"]:\n",
    "    save_img_label(ds, i, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.75 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov9s.pt, data=config.yaml, epochs=200, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1563475  ultralytics.nn.modules.head.Detect           [1, [128, 192, 256]]          \n",
      "YOLOv9s summary: 917 layers, 7,287,795 parameters, 7,287,779 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n"
     ]
    }
   ],
   "source": [
    "temp2 = model_9s.train(data = \"config.yaml\", epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we try to process all the datasets such that they are all only detecting other players. \n",
    "# essentially, we delete all the head categories, and force c and ct to be one group\n",
    "\n",
    "def process_line(line, delete_numbers, replace_map):\n",
    "    # Split the line by spaces\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) > 0:\n",
    "        parts = [float(item) for item in parts]\n",
    "        # If the first value is in the delete list, return None (to delete the line)\n",
    "        if parts[0] in delete_numbers:\n",
    "            return None\n",
    "        \n",
    "        # If the first value is in the replace_map, replace it with the corresponding value\n",
    "        if parts[0] in replace_map:\n",
    "            \n",
    "            parts[0] = replace_map[parts[0]]\n",
    "            \n",
    "        parts[0] = int(parts[0])\n",
    "        \n",
    "        parts = [str(item) for item in parts]\n",
    "    \n",
    "    # Return the modified line as a string\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def process_file(file_path, delete_numbers, replace_map):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Process each line in the file\n",
    "    modified_lines = []\n",
    "    for line in lines:\n",
    "        modified_line = process_line(line, delete_numbers, replace_map)\n",
    "        if modified_line is not None:\n",
    "            modified_lines.append(modified_line)\n",
    "    \n",
    "    # Write the modified lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(\"\\n\".join(modified_lines) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # names: ['CT', 'T'], we shall turn all the 1 into 0\n",
    "# dir = Path(r\"C:\\Users\\yangs\\Desktop\\training data\")\n",
    "\n",
    "# delete_numbers = []\n",
    "\n",
    "# replace_map = {1 : 0}\n",
    "\n",
    "# for i in [\"1\",\"2\", \"4\"]:\n",
    "#     for j in [\"test\", \"valid\", \"train\"]:\n",
    "#         temp_dir = dir / i / j / \"labels\"\n",
    "#         for filename in os.listdir(temp_dir):\n",
    "#             if filename.endswith('.txt'):\n",
    "#                 file_path = os.path.join(temp_dir, filename)\n",
    "#                 process_file(file_path, delete_numbers, replace_map)\n",
    "                \n",
    "# dir = Path(r\"C:\\Users\\yangs\\Desktop\\training data\")\n",
    "# target_dir = Path(r\"C:\\Users\\yangs\\Documents\\Python Projects\\YOLO-Head-Detection\\yolo_data\\labels\\train\")\n",
    "# for i in [\"1\",\"2\", \"4\"]:\n",
    "#     for j in [\"test\", \"valid\", \"train\"]:\n",
    "#         temp_dir = dir / i / j / \"labels\"\n",
    "#         for txt_file in temp_dir.glob(\"*.txt\"):\n",
    "#             # Copy the file to the target directory\n",
    "#             shutil.copy(txt_file, target_dir / txt_file.name)\n",
    "            \n",
    "# dir = Path(r\"C:\\Users\\yangs\\Desktop\\training data\")\n",
    "# target_dir = Path(r\"C:\\Users\\yangs\\Documents\\Python Projects\\YOLO-Head-Detection\\yolo_data\\images\\train\")\n",
    "# for i in [\"1\",\"2\", \"4\"]:\n",
    "#     for j in [\"test\", \"valid\", \"train\"]:\n",
    "#         temp_dir = dir / i / j / \"images\"\n",
    "#         for img_file in temp_dir.glob(\"*.JPG\"):\n",
    "#             # Copy the file to the target directory\n",
    "#             shutil.copy(img_file, target_dir / img_file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
